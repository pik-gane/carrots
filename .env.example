# Docker Compose Environment Variables
# Copy this file to .env and update with your values

# LLM Configuration (for Docker backend)
# Uncomment and configure one of the following options:

# Option 1: Ollama (Local, Free) - Recommended for testing
LLM_PROVIDER=ollama
LLM_MODEL=phi
OLLAMA_BASE_URL=http://host.docker.internal:11434
# Note for Linux: If host.docker.internal doesn't work, try: http://172.17.0.1:11434

# Option 2: OpenAI (Cloud, Paid)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4
# OPENAI_API_KEY=sk-your-actual-openai-api-key

# Option 3: Anthropic Claude (Cloud, Paid)
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-5-sonnet-20241022
# ANTHROPIC_API_KEY=sk-ant-your-actual-anthropic-key

# Placeholder for API key (required even if not used)
OPENAI_API_KEY=sk-placeholder
